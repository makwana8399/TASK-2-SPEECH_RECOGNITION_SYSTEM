# TASK-2-SPEECH_TO_TEXT

*COMPANY*: CODTECH IT SOLUTIONS

*NAME*: HARSHIL R. DARJI

*INTERN ID*: C0DF301

*DOMAIN*: Artificial Intelligence Markup Language.

*DURATION*: 4 WEEEKS

*NENTOR*: NEELA SANTOSH

# Speech-to-Text System – Project Overview
This Python script is a real-time speech-to-text converter that captures audio through a microphone, transcribes the speech using Google’s Web Speech API, and saves the raw audio into timestamped WAV files. Built using the speech_recognition library, it’s designed to be both a learning tool and a practical application for voice-based interaction. The core components include live microphone access, ambient noise adjustment, speech capturing, and transcription, all wrapped in an infinite loop for continuous use until manually stopped.

The code is particularly useful for students, researchers, journalists, or developers looking to transcribe interviews, record audio notes, or prototype voice-driven applications. Its modular design allows it to be easily extended for example, integrating a GUI, keyword detection, or other APIs like Whisper or Azure Speech Services. It also supports adding features like automatic audio playback, text logging, or saving to cloud storage.

In terms of tools and resources, this project was developed and debugged in Visual Studio Code (VS Code), which offered efficient code navigation, linting, and Git integration. ChatGPT served as a key learning companion throughout development, helping clarify concepts, resolve bugs, and refactor code for better readability and structure. For instance, when implementing ambient noise calibration and exception handling, ChatGPT provided detailed explanations and examples.

YouTube tutorials played a major role in the early stages especially videos focusing on Python voice assistants and audio processing. These tutorials offered practical, hands-on demonstrations of using the speech_recognition library, setting up virtual environments, and managing common microphone issues.

GeeksforGeeks was another valuable resource, especially for understanding how file handling works in Python, and for reinforcing basic concepts like string formatting and exception handling. Their concise, example-driven content helped bridge theory and practice quickly.

Community insights from Reddit, particularly subreddits like r/learnpython and r/Python, helped fine-tune aspects like choosing the right microphone index and managing edge cases where the speech recognizer might fail. These forums also provided recommendations for lightweight libraries and best practices for deploying speech applications.

In addition, this project benefited from personal guidance from experienced developers, who advised on structuring the code for clarity and maintainability. They emphasized separating logic into reusable functions, validating audio quality before saving, and planning for real-world challenges like handling silence or low-volume inputs.

Overall, this script serves as a solid starting point for anyone interested in voice interfaces, audio processing, or building assistive technologies. It brings together popular online learning resources, expert advice, and hands-on experimentation into a lightweight yet functional tool. Whether you’re looking to create your own voice assistant, build a dictation tool, or explore natural language processing, this project offers a simple yet effective launchpad.
